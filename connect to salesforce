# %%
!pip install simple-salesforce

# %%
import pandas as pd
import datetime
from simple_salesforce import Salesforce

# %%
from pyspark.sql.types import *
from pyspark.sql.functions import *

spark.conf.set("spark.sql.execution.arrow.pyspark.enabled", "false")

# %%
username = "sa_sf_edm@kindlymd.com"
password = "m7_)U(j<:e6-Sy7"
secret = "koUvyxL6oLtdQbE6CuOqH11d9"

# %%
sf = Salesforce(username=username, password=password, security_token=secret)

# %%
descAccount = sf.Account.describe()

account_field_names = [field['name'] for field in descAccount['fields']]

# %%
account_field_names

# %%
descAccount

# %%
account_sooql = "select {} from Account".format(','.join(account_field_names))
results = sfAccount.query_all(account_sooql)

# %%
dfAccount = pd.DataFrame(results['records'])
dfAccount.drop('attributes', axis=1, inplace=True, errors='ignore')

# %%
dfAccount.dropna(axis='columns', how='all', inplace=True)

# %%
sdfAccount = spark.createDataFrame(dfAccount)

# %%
sdfAccount.createOrReplaceTempView("sf")

# %%
%%sql
select * from sf limit 1000

# %%



